import streamlit as st
import pandas as pd
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import json
from datetime import datetime
import google.generativeai as genai
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# --- 1. ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="ìœ íŠœë¸Œ ê¸ˆìœµ ì¸ì‚¬ì´íŠ¸ DB", layout="wide")

# Gemini API ì„¤ì •
if "google_api_key" in st.secrets:
    genai.configure(api_key=st.secrets["google_api_key"])
else:
    st.error("ğŸš¨ Google API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Secretsë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

# --- 2. êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° í•¨ìˆ˜ ---
@st.cache_resource
def init_connection():
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    creds_dict = dict(st.secrets["gcp_service_account"])
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    client = gspread.authorize(creds)
    return client

def get_data():
    client = init_connection()
    sheet = client.open("Youtube_Data_Store").sheet1 
    data = sheet.get_all_records()
    return pd.DataFrame(data)

def save_data(row_data):
    client = init_connection()
    sheet = client.open("Youtube_Data_Store").sheet1
    sheet.append_row(row_data)
    # ë°ì´í„°ê°€ ê°±ì‹ ë˜ì—ˆìœ¼ë¯€ë¡œ ìºì‹œ ì‚­ì œ (ì±—ë´‡ì´ ìƒˆ ë°ì´í„°ë¥¼ ì•Œê²Œ í•¨)
    st.cache_resource.clear()

# --- 3. ê²€ìƒ‰ ì—”ì§„ (TF-IDF) ---
def search_documents(query, df, top_k=3):
    if df.empty:
        return []
    
    # ê²€ìƒ‰ ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ 'ì£¼ì¥'ê³¼ 'ì‹œì‚¬ì 'ê¹Œì§€ ê²€ìƒ‰ ë²”ìœ„ì— í¬í•¨
    df['combined_text'] = (
        df['ì œëª©'].astype(str) + " " + 
        df['í•µì‹¬ì£¼ì œ'].astype(str) + " " + 
        df['í•µì‹¬ì£¼ì¥'].astype(str) + " " + 
        df['ì‹œì‚¬ì '].astype(str) + " " + 
        df['ìš”ì•½'].astype(str)
    )
    
    tfidf = TfidfVectorizer()
    try:
        tfidf_matrix = tfidf.fit_transform(df['combined_text'])
        query_vec = tfidf.transform([query])
        cosine_sim = cosine_similarity(query_vec, tfidf_matrix).flatten()
        top_indices = cosine_sim.argsort()[-top_k:][::-1]
        
        results = []
        for idx in top_indices:
            if cosine_sim[idx] > 0:
                results.append(df.iloc[idx])
        return results
    except ValueError:
        return []

# --- 4. ë©”ì¸ UI ---
st.title("ğŸ“º ìœ íŠœë¸Œ ê¸ˆìœµ ì¸ì‚¬ì´íŠ¸ ì €ì¥ì†Œ (Full Ver.)")

tab1, tab2 = st.tabs(["ğŸ“¥ ë°ì´í„° ì…ë ¥", "ğŸ¤– AI ì±—ë´‡"])

# === [íƒ­ 1] ë°ì´í„° ì…ë ¥ ===
with tab1:
    st.subheader("Gemini ë¶„ì„ ë°ì´í„° ì ì¬")
    st.info("ğŸ’¡ JSONì˜ ëª¨ë“  ì •ë³´(ì£¼ì¥, ê·¼ê±°, ì‹œì‚¬ì  ë“±)ë¥¼ ë¹ ì§ì—†ì´ ì €ì¥í•©ë‹ˆë‹¤.")
    
    with st.form("data_input_form"):
        json_input = st.text_area("JSON Input", height=200, placeholder="Geminiê°€ ì¤€ JSON ì½”ë“œë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.")
        submitted = st.form_submit_button("DB ì €ì¥í•˜ê¸°")

    if submitted and json_input:
        try:
            data = json.loads(json_input)
            
            # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ë°ì´í„°(ì£¼ì¥, ê·¼ê±°)ë¥¼ ì¤„ë°”ê¿ˆ ë¬¸ìì—´ë¡œ ë³€í™˜
            key_arguments = "\n- ".join(data.get("key_arguments", []))
            if key_arguments: key_arguments = "- " + key_arguments
            
            evidence = "\n- ".join(data.get("evidence", []))
            if evidence: evidence = "- " + evidence

            # êµ¬ê¸€ ì‹œíŠ¸ ì»¬ëŸ¼ ìˆœì„œì— ë§ì¶° ë°ì´í„° ì¤€ë¹„ (14ê°œ í•­ëª©)
            row_data = [
                datetime.now().strftime("%Y-%m-%d %H:%M:%S"), # A: ìˆ˜ì§‘ì¼ì‹œ
                data.get("published_at", ""),                 # B: ì—…ë¡œë“œì¼
                data.get("video_id", ""),                     # C: ì˜ìƒID
                data.get("title", ""),                        # D: ì œëª©
                data.get("channel_name", ""),                 # E: ì±„ë„ëª…
                data.get("main_topic", ""),                   # F: í•µì‹¬ì£¼ì œ
                key_arguments,                                # G: í•µì‹¬ì£¼ì¥ (ìƒì„¸)
                evidence,                                     # H: ê·¼ê±° (ìƒì„¸)
                data.get("implications", ""),                 # I: ì‹œì‚¬ì 
                data.get("validity_check", ""),               # J: íƒ€ë‹¹ì„±
                data.get("sentiment", ""),                    # K: ê°ì •
                data.get("full_summary", ""),                 # L: ìš”ì•½
                data.get("tags", ""),                         # M: íƒœê·¸
                data.get("url", "")                           # N: URL
            ]
            
            save_data(row_data)
            st.success(f"âœ… ëª¨ë“  ìƒì„¸ ì •ë³´ ì €ì¥ ì™„ë£Œ: {data.get('title')}")
            
        except json.JSONDecodeError:
            st.error("âŒ JSON í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"âŒ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# === [íƒ­ 2] AI ì±—ë´‡ ===
with tab2:
    st.subheader("ë‚´ ê¸ˆìœµ ë°ì´í„°ì™€ ëŒ€í™”í•˜ê¸°")
    
    try:
        df = get_data()
        st.caption(f"ğŸ“š í˜„ì¬ ì´ {len(df)}ê°œì˜ ì‹¬ì¸µ ë¶„ì„ ë°ì´í„°ê°€ í•™ìŠµë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    except:
        st.warning("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. êµ¬ê¸€ ì‹œíŠ¸ í—¤ë”(1í–‰)ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    if "messages" not in st.session_state:
        st.session_state["messages"] = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ì €ì¥ëœ ì‹¬ì¸µ ë¶„ì„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ ë“œë¦´ê²Œìš”."}]

    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.chat_message("user").write(prompt)

        with st.spinner("Geminiê°€ ì¸ì‚¬ì´íŠ¸ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            relevant_rows = search_documents(prompt, df)
            
            if not relevant_rows:
                response_text = "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ë‚´ìš©ì„ DBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            else:
                context_str = ""
                for idx, row in enumerate(relevant_rows):
                    # ì±—ë´‡ì—ê²Œ ë” í’ë¶€í•œ ì •ë³´ë¥¼ ì¤ë‹ˆë‹¤
                    context_str += f"""
                    [ì°¸ê³  ì˜ìƒ {idx+1}]
                    - ì œëª©: {row['ì œëª©']} (ì±„ë„: {row['ì±„ë„ëª…']})
                    - í•µì‹¬ì£¼ì¥: {row['í•µì‹¬ì£¼ì¥']}
                    - ì‹œì‚¬ì : {row['ì‹œì‚¬ì ']}
                    - íƒ€ë‹¹ì„± í‰ê°€: {row['íƒ€ë‹¹ì„±']}
                    - ìš”ì•½: {row['ìš”ì•½']}
                    """
                
                system_prompt = f"""
                ë‹¹ì‹ ì€ ì „ë¬¸ íˆ¬ì ìë¬¸ AIì…ë‹ˆë‹¤. ì•„ë˜ [ì°¸ê³  ì˜ìƒ]ì˜ ì‹¬ì¸µ ë¶„ì„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
                ë‹¨ìˆœí•œ ìš”ì•½ë³´ë‹¤ëŠ” 'í•µì‹¬ ì£¼ì¥', 'ì‹œì‚¬ì ', 'ê·¼ê±°'ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë…¼ë¦¬ì ì¸ ë‹µë³€ì„ í•˜ì„¸ìš”.
                
                [ì°¸ê³  ì˜ìƒ ë°ì´í„°]
                {context_str}
                
                [ì§ˆë¬¸]
                {prompt}
                """
                
                try:
                    model = genai.GenerativeModel('gemini-2.5-flash')
                    response = model.generate_content(system_prompt)
                    response_text = response.text
                except Exception as e:
                    response_text = f"AI ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}"

        st.session_state.messages.append({"role": "assistant", "content": response_text})
        st.chat_message("assistant").write(response_text)
